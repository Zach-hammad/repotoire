{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Cypher Queries with Falkor\n",
    "\n",
    "This notebook demonstrates how to write custom Cypher queries to explore your codebase knowledge graph.\n",
    "\n",
    "Topics covered:\n",
    "1. Basic graph traversal\n",
    "2. Finding dependencies\n",
    "3. Analyzing complexity hotspots\n",
    "4. Discovering patterns\n",
    "5. Performance optimization tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, connect to Neo4j and ensure you have data from a previous ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from falkor.graph import Neo4jClient\n",
    "from falkor.config import load_config\n",
    "import pandas as pd\n",
    "\n",
    "# Load config and connect\n",
    "config = load_config()\n",
    "db = Neo4jClient(\n",
    "    uri=config.neo4j.uri,\n",
    "    username=config.neo4j.user,\n",
    "    password=config.neo4j.password\n",
    ")\n",
    "\n",
    "# Verify connection\n",
    "stats = db.get_stats()\n",
    "print(f\"✓ Connected. Graph contains {stats['total_nodes']} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Graph Traversal\n",
    "\n",
    "Let's start with simple queries to understand the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all files in the codebase\n",
    "query = \"\"\"\n",
    "MATCH (f:File)\n",
    "RETURN f.filePath AS path, \n",
    "       f.language AS language, \n",
    "       f.loc AS lines_of_code\n",
    "ORDER BY f.loc DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nTop 10 Largest Files:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all classes with their method counts\n",
    "query = \"\"\"\n",
    "MATCH (f:File)-[:CONTAINS]->(c:Class)\n",
    "OPTIONAL MATCH (f)-[:CONTAINS]->(m:Function)\n",
    "WHERE m.qualifiedName STARTS WITH c.qualifiedName + '.'\n",
    "WITH c, f, count(m) AS method_count\n",
    "RETURN c.name AS class_name,\n",
    "       f.filePath AS file,\n",
    "       method_count,\n",
    "       c.complexity AS complexity\n",
    "ORDER BY method_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nClasses with Most Methods:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding Dependencies\n",
    "\n",
    "Explore import relationships and dependencies between files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files with most imports (highly coupled)\n",
    "query = \"\"\"\n",
    "MATCH (f:File)-[:IMPORTS]->(m:Module)\n",
    "WITH f, count(DISTINCT m) AS import_count\n",
    "RETURN f.filePath AS file,\n",
    "       import_count\n",
    "ORDER BY import_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nFiles with Most Imports (High Coupling):\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most imported modules (highly depended upon)\n",
    "query = \"\"\"\n",
    "MATCH (f:File)-[:IMPORTS]->(m:Module)\n",
    "WHERE m.is_external = false\n",
    "WITH m, collect(DISTINCT f.filePath) AS importers\n",
    "RETURN m.qualifiedName AS module,\n",
    "       size(importers) AS imported_by_count,\n",
    "       importers[..3] AS sample_importers\n",
    "ORDER BY imported_by_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nMost Depended-Upon Internal Modules:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dependency chains (A imports B imports C)\n",
    "query = \"\"\"\n",
    "MATCH path = (f1:File)-[:IMPORTS*2..3]->(f2:File)\n",
    "WHERE f1 <> f2\n",
    "RETURN [node IN nodes(path) | node.filePath] AS dependency_chain,\n",
    "       length(path) AS chain_length\n",
    "ORDER BY chain_length DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "print(\"\\nLong Dependency Chains:\")\n",
    "for i, record in enumerate(result[:5], 1):\n",
    "    chain = record['dependency_chain']\n",
    "    print(f\"\\n{i}. Chain length: {record['chain_length']}\")\n",
    "    for j, file in enumerate(chain, 1):\n",
    "        print(f\"   {j}. {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyzing Complexity Hotspots\n",
    "\n",
    "Find the most complex parts of your codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most complex functions\n",
    "query = \"\"\"\n",
    "MATCH (f:File)-[:CONTAINS]->(func:Function)\n",
    "RETURN func.name AS function,\n",
    "       f.filePath AS file,\n",
    "       func.complexity AS complexity,\n",
    "       func.lineStart AS line,\n",
    "       size(func.parameters) AS param_count\n",
    "ORDER BY func.complexity DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nMost Complex Functions:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find complexity distribution by file\n",
    "query = \"\"\"\n",
    "MATCH (file:File)-[:CONTAINS]->(func:Function)\n",
    "WITH file, \n",
    "     sum(func.complexity) AS total_complexity,\n",
    "     count(func) AS function_count,\n",
    "     avg(func.complexity) AS avg_complexity\n",
    "RETURN file.filePath AS file,\n",
    "       total_complexity,\n",
    "       function_count,\n",
    "       round(avg_complexity, 2) AS avg_complexity\n",
    "ORDER BY total_complexity DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nFiles with Highest Total Complexity:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discovering Patterns\n",
    "\n",
    "Find interesting patterns in your codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find functions that call many other functions (fan-out)\n",
    "query = \"\"\"\n",
    "MATCH (f:Function)-[:CALLS]->(called)\n",
    "WITH f, count(DISTINCT called) AS call_count\n",
    "WHERE call_count > 5\n",
    "RETURN f.name AS function,\n",
    "       f.filePath AS file,\n",
    "       call_count,\n",
    "       f.complexity AS complexity\n",
    "ORDER BY call_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nFunctions with High Fan-Out:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find utility functions (called by many others)\n",
    "query = \"\"\"\n",
    "MATCH (caller:Function)-[:CALLS]->(f:Function)\n",
    "WITH f, count(DISTINCT caller) AS caller_count\n",
    "WHERE caller_count > 3\n",
    "RETURN f.name AS function,\n",
    "       f.filePath AS file,\n",
    "       caller_count,\n",
    "       f.complexity AS complexity\n",
    "ORDER BY caller_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nUtility Functions (High Fan-In):\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find classes with inheritance chains\n",
    "query = \"\"\"\n",
    "MATCH path = (child:Class)-[:INHERITS*1..5]->(parent:Class)\n",
    "RETURN child.name AS child_class,\n",
    "       [node IN nodes(path) | node.name] AS inheritance_chain,\n",
    "       length(path) AS depth\n",
    "ORDER BY depth DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "print(\"\\nDeep Inheritance Hierarchies:\")\n",
    "for i, record in enumerate(result[:5], 1):\n",
    "    chain = record['inheritance_chain']\n",
    "    print(f\"\\n{i}. Depth: {record['depth']}\")\n",
    "    print(f\"   {' -> '.join(chain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find methods that override parent methods\n",
    "query = \"\"\"\n",
    "MATCH (child_method:Function)-[:OVERRIDES]->(parent_method:Function)\n",
    "MATCH (child_class:Class)-[:INHERITS]->(parent_class:Class)\n",
    "WHERE child_method.qualifiedName STARTS WITH child_class.qualifiedName\n",
    "  AND parent_method.qualifiedName STARTS WITH parent_class.qualifiedName\n",
    "RETURN child_method.name AS method_name,\n",
    "       child_class.name AS child_class,\n",
    "       parent_class.name AS parent_class,\n",
    "       child_method.complexity AS child_complexity,\n",
    "       parent_method.complexity AS parent_complexity\n",
    "ORDER BY child_method.name\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nMethod Overrides:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Analysis Patterns\n",
    "\n",
    "More complex queries for deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cohesion within files (functions calling each other in same file)\n",
    "query = \"\"\"\n",
    "MATCH (file:File)-[:CONTAINS]->(f1:Function),\n",
    "      (file)-[:CONTAINS]->(f2:Function)\n",
    "WHERE f1 <> f2\n",
    "OPTIONAL MATCH (f1)-[:CALLS]->(f2)\n",
    "WITH file, \n",
    "     count(DISTINCT f1) AS total_functions,\n",
    "     count((f1)-[:CALLS]->(f2)) AS internal_calls\n",
    "WHERE total_functions > 2\n",
    "RETURN file.filePath AS file,\n",
    "       total_functions,\n",
    "       internal_calls,\n",
    "       round(toFloat(internal_calls) / (total_functions * (total_functions - 1)), 3) AS cohesion\n",
    "ORDER BY cohesion DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nFiles with High Internal Cohesion:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bottleneck functions (high betweenness centrality)\n",
    "query = \"\"\"\n",
    "MATCH (f:Function)\n",
    "OPTIONAL MATCH (caller)-[:CALLS]->(f)\n",
    "OPTIONAL MATCH (f)-[:CALLS]->(callee)\n",
    "WITH f,\n",
    "     count(DISTINCT caller) AS in_degree,\n",
    "     count(DISTINCT callee) AS out_degree\n",
    "WHERE in_degree > 2 AND out_degree > 2\n",
    "RETURN f.name AS function,\n",
    "       f.filePath AS file,\n",
    "       in_degree,\n",
    "       out_degree,\n",
    "       in_degree * out_degree AS centrality_score\n",
    "ORDER BY centrality_score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nBottleneck Functions (High Centrality):\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find decorator usage patterns\n",
    "query = \"\"\"\n",
    "MATCH (f:Function)\n",
    "WHERE size(f.decorators) > 0\n",
    "UNWIND f.decorators AS decorator\n",
    "RETURN decorator,\n",
    "       count(*) AS usage_count,\n",
    "       collect(DISTINCT f.name)[..5] AS example_functions\n",
    "ORDER BY usage_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nMost Used Decorators:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Optimization Tips\n",
    "\n",
    "Guidelines for writing efficient Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EXPLAIN or PROFILE to understand query execution\n",
    "query = \"\"\"\n",
    "EXPLAIN\n",
    "MATCH (f:Function)\n",
    "WHERE f.complexity > 10\n",
    "RETURN f.name, f.complexity\n",
    "ORDER BY f.complexity DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "print(\"Query execution plan generated (see Neo4j Browser for details)\")\n",
    "print(\"\\nTips:\")\n",
    "print(\"- Use indexes on frequently queried properties\")\n",
    "print(\"- Filter early with WHERE clauses\")\n",
    "print(\"- Limit relationship traversal depth\")\n",
    "print(\"- Use PROFILE to see actual query performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Analysis Examples\n",
    "\n",
    "Combine patterns to answer specific questions about your codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Which files have the highest \"change risk\"?\n",
    "# (High complexity + high coupling + many dependencies)\n",
    "\n",
    "query = \"\"\"\n",
    "MATCH (file:File)\n",
    "OPTIONAL MATCH (file)-[:CONTAINS]->(func:Function)\n",
    "OPTIONAL MATCH (file)-[:IMPORTS]->(module)\n",
    "OPTIONAL MATCH (other_file:File)-[:IMPORTS]->(file)\n",
    "WITH file,\n",
    "     sum(func.complexity) AS total_complexity,\n",
    "     count(DISTINCT module) AS import_count,\n",
    "     count(DISTINCT other_file) AS imported_by_count\n",
    "WITH file,\n",
    "     total_complexity,\n",
    "     import_count,\n",
    "     imported_by_count,\n",
    "     (total_complexity * 0.4 + import_count * 10 + imported_by_count * 15) AS risk_score\n",
    "RETURN file.filePath AS file,\n",
    "       total_complexity,\n",
    "       import_count,\n",
    "       imported_by_count,\n",
    "       round(risk_score) AS risk_score\n",
    "ORDER BY risk_score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = db.execute_query(query)\n",
    "df = pd.DataFrame(result)\n",
    "print(\"\\nFiles with Highest Change Risk:\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"\\nRisk factors: complexity, coupling (imports), dependents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()\n",
    "print(\"✓ Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Basic Traversal**: How to navigate the knowledge graph\n",
    "2. **Dependencies**: Finding import relationships and coupling\n",
    "3. **Complexity**: Identifying complexity hotspots\n",
    "4. **Patterns**: Discovering common code patterns\n",
    "5. **Advanced Analysis**: Cohesion, centrality, custom metrics\n",
    "6. **Performance**: Query optimization techniques\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Neo4j Cypher Documentation](https://neo4j.com/docs/cypher-manual/current/)\n",
    "- [Graph Data Science Library](https://neo4j.com/docs/graph-data-science/current/)\n",
    "- Falkor Schema: See `falkor/graph/schema.py`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try `03_visualization.ipynb` for graph visualization\n",
    "- Explore `04_batch_analysis.ipynb` for multi-project analysis\n",
    "- Write your own queries to answer specific questions about your codebase!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
