{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falkor Basic Analysis Workflow\n",
    "\n",
    "This notebook demonstrates the basic workflow for analyzing a codebase with Falkor:\n",
    "\n",
    "1. Setting up connections\n",
    "2. Ingesting a codebase\n",
    "3. Running analysis\n",
    "4. Understanding the health report\n",
    "5. Exploring findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's import Falkor and configure our connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from pathlib import Path\n",
    "from falkor.graph import Neo4jClient, GraphSchema\n",
    "from falkor.pipeline import IngestionPipeline\n",
    "from falkor.detectors import AnalysisEngine\n",
    "from falkor.config import load_config\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration (or use defaults)\n",
    "config = load_config()\n",
    "\n",
    "# Connect to Neo4j\n",
    "neo4j_client = Neo4jClient(\n",
    "    uri=config.neo4j.uri,\n",
    "    username=config.neo4j.user,\n",
    "    password=config.neo4j.password,\n",
    "    max_retries=config.neo4j.max_retries\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Connected to Neo4j at {config.neo4j.uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ingest a Codebase\n",
    "\n",
    "Let's ingest a sample codebase into the knowledge graph. Replace `/path/to/repo` with your actual repository path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the repository to analyze\n",
    "repo_path = \"/path/to/your/repo\"\n",
    "\n",
    "# Create ingestion pipeline\n",
    "pipeline = IngestionPipeline(\n",
    "    repo_path=repo_path,\n",
    "    neo4j_client=neo4j_client,\n",
    "    follow_symlinks=False,  # Security: don't follow symlinks\n",
    "    max_file_size_mb=10,\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Created ingestion pipeline for {repo_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ingestion with progress tracking\n",
    "def progress_callback(current, total, filename):\n",
    "    if current % 10 == 0:  # Print every 10 files\n",
    "        percentage = (current / total) * 100\n",
    "        print(f\"Progress: {current}/{total} ({percentage:.1f}%) - {Path(filename).name}\")\n",
    "\n",
    "# Ingest the codebase\n",
    "pipeline.ingest(\n",
    "    patterns=[\"**/*.py\"],  # Python files only\n",
    "    progress_callback=progress_callback\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Ingestion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what was ingested\n",
    "stats = neo4j_client.get_stats()\n",
    "\n",
    "print(\"\\nðŸ“Š Graph Statistics:\")\n",
    "print(f\"  Files: {stats['total_files']}\")\n",
    "print(f\"  Classes: {stats['total_classes']}\")\n",
    "print(f\"  Functions: {stats['total_functions']}\")\n",
    "print(f\"  Total Nodes: {stats['total_nodes']}\")\n",
    "print(f\"  Relationships: {stats['total_relationships']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Analysis\n",
    "\n",
    "Now let's run the analysis engine to detect code smells and calculate health scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis engine\n",
    "engine = AnalysisEngine(\n",
    "    neo4j_client=neo4j_client,\n",
    "    detector_config=config.detectors.__dict__ if hasattr(config, 'detectors') else None\n",
    ")\n",
    "\n",
    "# Run analysis\n",
    "print(\"Running analysis...\")\n",
    "health = engine.analyze()\n",
    "\n",
    "print(f\"\\nâœ“ Analysis complete! Grade: {health.grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding the Health Report\n",
    "\n",
    "The health report contains:\n",
    "- Overall grade (A-F)\n",
    "- Category scores (Structure, Quality, Architecture)\n",
    "- Detailed metrics\n",
    "- Findings by severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display overall health\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"CODEBASE HEALTH REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOverall Grade: {health.grade}\")\n",
    "print(f\"Overall Score: {health.overall_score:.1f}/100\\n\")\n",
    "\n",
    "# Category scores\n",
    "print(\"Category Scores:\")\n",
    "print(f\"  Structure    (40% weight): {health.structure_score:.1f}/100\")\n",
    "print(f\"  Quality      (30% weight): {health.quality_score:.1f}/100\")\n",
    "print(f\"  Architecture (30% weight): {health.architecture_score:.1f}/100\")\n",
    "\n",
    "# Findings summary\n",
    "print(f\"\\nFindings Summary:\")\n",
    "print(f\"  Critical: {health.findings_summary.critical}\")\n",
    "print(f\"  High:     {health.findings_summary.high}\")\n",
    "print(f\"  Medium:   {health.findings_summary.medium}\")\n",
    "print(f\"  Low:      {health.findings_summary.low}\")\n",
    "print(f\"  Info:     {health.findings_summary.info}\")\n",
    "print(f\"  Total:    {health.findings_summary.total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed metrics\n",
    "m = health.metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nStructure Metrics:\")\n",
    "print(f\"  Modularity:             {m.modularity:.2f} (0.3-0.7 is good)\")\n",
    "print(f\"  Average Coupling:       {m.avg_coupling:.1f} (lower is better)\")\n",
    "print(f\"  Circular Dependencies:  {m.circular_dependencies}\")\n",
    "print(f\"  Bottleneck Count:       {m.bottleneck_count}\")\n",
    "\n",
    "print(\"\\nQuality Metrics:\")\n",
    "print(f\"  Dead Code:              {m.dead_code_percentage*100:.1f}%\")\n",
    "print(f\"  Duplication:            {m.duplication_percentage*100:.1f}%\")\n",
    "print(f\"  God Classes:            {m.god_class_count}\")\n",
    "\n",
    "print(\"\\nArchitecture Metrics:\")\n",
    "print(f\"  Layer Violations:       {m.layer_violations}\")\n",
    "print(f\"  Boundary Violations:    {m.boundary_violations}\")\n",
    "print(f\"  Abstraction Ratio:      {m.abstraction_ratio:.2f} (0.3-0.7 is good)\")\n",
    "\n",
    "print(\"\\nCodebase Statistics:\")\n",
    "print(f\"  Total Files:            {m.total_files}\")\n",
    "print(f\"  Total Classes:          {m.total_classes}\")\n",
    "print(f\"  Total Functions:        {m.total_functions}\")\n",
    "print(f\"  Total LOC:              {m.total_loc:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploring Findings\n",
    "\n",
    "Let's examine the findings in detail, starting with the highest severity issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort findings by severity\n",
    "severity_order = {\"critical\": 0, \"high\": 1, \"medium\": 2, \"low\": 3, \"info\": 4}\n",
    "sorted_findings = sorted(\n",
    "    health.findings,\n",
    "    key=lambda f: severity_order.get(f.severity.value, 5)\n",
    ")\n",
    "\n",
    "# Display top 5 findings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, finding in enumerate(sorted_findings[:5], 1):\n",
    "    print(f\"\\n{i}. [{finding.severity.value.upper()}] {finding.title}\")\n",
    "    print(f\"   Detector: {finding.detector}\")\n",
    "    print(f\"   Files affected: {len(finding.affected_files)}\")\n",
    "    print(f\"   Description: {finding.description[:100]}...\")\n",
    "    if finding.suggested_fix:\n",
    "        print(f\"   Fix: {finding.suggested_fix[:80]}...\")\n",
    "    print(f\"   Effort: {finding.estimated_effort}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of a specific finding\n",
    "if sorted_findings:\n",
    "    finding = sorted_findings[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"DETAILED FINDING: {finding.title}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nID: {finding.id}\")\n",
    "    print(f\"Detector: {finding.detector}\")\n",
    "    print(f\"Severity: {finding.severity.value.upper()}\")\n",
    "    print(f\"\\nDescription:\\n{finding.description}\")\n",
    "    \n",
    "    print(f\"\\nAffected Files ({len(finding.affected_files)}):\")\n",
    "    for file in finding.affected_files[:5]:\n",
    "        print(f\"  - {file}\")\n",
    "    \n",
    "    if finding.suggested_fix:\n",
    "        print(f\"\\nSuggested Fix:\\n{finding.suggested_fix}\")\n",
    "    \n",
    "    print(f\"\\nEstimated Effort: {finding.estimated_effort}\")\n",
    "    \n",
    "    print(f\"\\nGraph Context:\")\n",
    "    for key, value in finding.graph_context.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results\n",
    "\n",
    "Save the health report for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "output_file = \"health_report.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(health.to_dict(), f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Health report saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to HTML report\n",
    "from falkor.reporters import HTMLReporter\n",
    "\n",
    "reporter = HTMLReporter(repo_path=Path(repo_path))\n",
    "reporter.generate(health, \"health_report.html\")\n",
    "\n",
    "print(\"âœ“ HTML report generated: health_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "Close the database connection when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_client.close()\n",
    "print(\"âœ“ Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Check out `02_custom_queries.ipynb` to learn how to write custom Cypher queries\n",
    "- See `03_visualization.ipynb` for graph visualization techniques\n",
    "- Explore `04_batch_analysis.ipynb` for analyzing multiple codebases\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. Configure and connect to Neo4j\n",
    "2. Ingest a codebase into the knowledge graph\n",
    "3. Run the analysis engine\n",
    "4. Interpret health scores and metrics\n",
    "5. Explore findings and get actionable insights\n",
    "6. Export results in multiple formats\n",
    "\n",
    "Falkor provides a comprehensive view of your codebase health through graph-based analysis. Use these insights to prioritize refactoring efforts and improve code quality!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
