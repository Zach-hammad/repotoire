# Repotoire ğŸ¼

**Graph-powered code analysis. 114 detectors. 13 languages. One binary.**

Repotoire builds a knowledge graph of your codebase and runs 114 detectors to find security vulnerabilities, architectural issues, and code smells that file-by-file linters miss.

[![Crates.io](https://img.shields.io/crates/v/repotoire.svg)](https://crates.io/crates/repotoire)
[![CI](https://github.com/Zach-hammad/repotoire/actions/workflows/ci.yml/badge.svg)](https://github.com/Zach-hammad/repotoire/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

```bash
cargo install repotoire
repotoire analyze .
```

No API keys. No Docker. No cloud account. **Pure Rust, ~24MB binary.**

---

## What It Finds

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Traditional linters see files.  Repotoire sees the graph.  â”‚
â”‚                                                              â”‚
â”‚  file1.rs â”€â”€â”                                                â”‚
â”‚  file2.go â”€â”€â”¼â”€â”€ Knowledge Graph â”€â”€ 114 Detectors             â”‚
â”‚  file3.ts â”€â”€â”˜         â”‚                                      â”‚
â”‚                  Circular deps? God classes? Dead code?       â”‚
â”‚                  SQL injection? Taint flow? Bottlenecks?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”’ Security (25+ detectors)
SQL/NoSQL injection Â· XSS Â· SSRF Â· XXE Â· Command injection Â· Path traversal Â· Hardcoded secrets Â· Insecure crypto Â· Weak JWT Â· Prototype pollution Â· Insecure deserialization Â· Insecure TLS Â· Dependency vulnerabilities (OSV.dev)

### ğŸ—ï¸ Architecture (15+ detectors)
Circular dependencies (Tarjan's SCC) Â· Architectural bottlenecks (betweenness centrality) Â· God classes Â· Feature envy Â· Hub dependencies Â· Dead code Â· Import cycles Â· Delegation chains

### ğŸ› Bug Risk (15+ detectors)
Missing await Â· Unhandled promises Â· Mutable default args Â· Implicit coercion Â· React hooks violations Â· Inconsistent returns Â· Infinite loops

### ğŸ§¹ Quality (30+ detectors)
Deep nesting Â· Long methods Â· Magic numbers Â· Duplicate code Â· AI-generated boilerplate detection Â· Naming patterns Â· Complexity spikes Â· Churn analysis

### âš¡ Performance (10+ detectors)
N+1 queries Â· Sync in async Â· String concat in loops Â· Regex compilation in loops Â· Callback hell

## Languages

**Full graph analysis (tree-sitter):** Python Â· TypeScript Â· JavaScript Â· Go Â· Java Â· Rust Â· C Â· C++ Â· C#

**Security/quality scanning:** Ruby Â· PHP Â· Kotlin Â· Swift (regex-based detectors)

## Install

```bash
# From crates.io (requires Rust toolchain)
cargo install repotoire

# From source
git clone https://github.com/Zach-hammad/repotoire
cd repotoire/repotoire-cli
cargo build --release

# Binary download (Linux x86_64)
curl -L https://github.com/Zach-hammad/repotoire/releases/latest/download/repotoire-linux-x86_64.tar.gz | tar xz
sudo mv repotoire /usr/local/bin/

# Homebrew (macOS)
brew tap Zach-hammad/repotoire
brew install repotoire
```

## Usage

```bash
# Analyze current directory
repotoire analyze .

# Only high/critical findings
repotoire analyze . --relaxed

# Output formats
repotoire analyze . --format json
repotoire analyze . --format html --output report.html
repotoire analyze . --format sarif --output results.sarif
repotoire analyze . --format markdown

# CI: fail if high-severity findings exist
repotoire analyze . --fail-on high

# Skip slow parts for huge repos
repotoire analyze . --lite

# Interactive findings browser
repotoire findings -i

# AI-powered fixes (optional, requires API key)
repotoire fix <finding-id>

# Adaptive thresholds â€” learns YOUR coding style
repotoire calibrate .    # explicit (optional â€” auto-runs on first analyze)
repotoire analyze .      # auto-calibrates if no profile exists

# Scoring breakdown
repotoire analyze . --explain-score

# Check your setup
repotoire doctor
```

## Sample Output

```
ğŸ¼ Repotoire Analysis

ğŸ“ 456 files  âš™ï¸  4,348 functions  ğŸ›ï¸  778 classes

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Health Report â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Grade: B           Score: 82.5/100                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” Findings (127 total)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ Critical â”‚     2 â”‚
â”‚ ğŸŸ  High     â”‚    12 â”‚
â”‚ ğŸŸ¡ Medium   â”‚    45 â”‚
â”‚ ğŸ”µ Low      â”‚    68 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

âœ¨ Analysis complete in 2.05s
```

## CI/CD

### GitHub Actions (recommended)

```yaml
name: Code Quality
on: [pull_request]

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2

      - name: Install Repotoire
        run: cargo install repotoire

      - name: Analyze
        run: repotoire analyze . --fail-on high
```

### SARIF (GitHub Code Scanning)

```yaml
      - name: Analyze
        run: repotoire analyze . --format sarif --output results.sarif

      - uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: results.sarif
```

### Pre-commit

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: repotoire
        name: repotoire
        entry: repotoire analyze . --fail-on high --no-emoji
        language: system
        pass_filenames: false
```

## Adaptive Thresholds

Repotoire learns YOUR coding patterns. Instead of arbitrary defaults, it analyzes your codebase's statistical distribution and flags only outliers from your style.

```bash
repotoire calibrate .   # Generate style profile (optional â€” auto-runs on first analyze)
```

On first `analyze`, repotoire auto-calibrates and saves a profile to `.repotoire/style-profile.json`:

```
ğŸ“Š Style Profile (your-project, 2886 functions)

  complexity      mean=4.7  p90=12  p95=17
  nesting_depth   mean=1.4  p90=4   p95=5
  function_length mean=24   p90=60  p95=91
  file_length     mean=408  p90=773 p95=915
  parameter_count mean=1.5  p90=3   p95=4
```

Detectors use `max(default, your_p90)` as thresholds â€” they only go UP, never down. A messy codebase gets more lenient thresholds (flag only YOUR outliers), while a clean codebase stays at defaults.

**Detectors with adaptive thresholds:** DeepNesting, LargeFiles, GodClass, LongParameterList, ArchitecturalBottleneck.

## Configuration

Create `repotoire.toml` in your repo root (or run `repotoire init`):

```toml
# Exclude paths
[exclude]
paths = ["generated/", "vendor/", "third_party/"]

# Override detector thresholds
[detectors.god-class]
thresholds = { critical_methods = 30, critical_lines = 1000 }

[detectors.deep-nesting]
thresholds = { high_severity_depth = 6 }

[detectors.dead-code]
enabled = false  # Disable entirely

# Scoring weights
[scoring]
pillar_weights = { structure = 0.30, quality = 0.40, architecture = 0.30 }
```

## AI Fixes (Optional)

Bring your own API key for AI-assisted code fixes:

```bash
# Any of these (pick one):
export ANTHROPIC_API_KEY=sk-ant-...    # Claude
export OPENAI_API_KEY=sk-...           # GPT-4
export DEEPINFRA_API_KEY=...           # Llama (cheapest)
export OPENROUTER_API_KEY=...          # Any model

# Or 100% local with Ollama:
ollama pull deepseek-coder:6.7b
repotoire fix <finding-id>
```

No API key? No problem. All 114 detectors work fully offline.

## How It Works

```
Source Files â”€â”€â–¶ Tree-sitter â”€â”€â–¶ Knowledge Graph â”€â”€â–¶ 114 Detectors
(13 languages)    (parallel)     (petgraph + redb)    (parallel)
                                       â”‚
                                 Graph algorithms:
                                 â€¢ Tarjan's SCC
                                 â€¢ Betweenness centrality
                                 â€¢ SSA taint analysis
                                 â€¢ PageRank
                                       â”‚
                                       â–¼
                                  CLI / HTML / JSON / SARIF / Markdown
```

**Stack:** Tree-sitter (parsing) Â· petgraph (graphs) Â· redb (cache) Â· rayon (parallelism) Â· ureq (HTTP, optional)

## vs Others

| | Repotoire | SonarQube | Semgrep |
|---|---|---|---|
| Local-first | âœ… | âŒ (server) | âœ… |
| No Docker | âœ… | âŒ | âœ… |
| Graph analysis | âœ… | Partial | âŒ |
| Taint analysis | âœ… (SSA) | âœ… | âœ… |
| Circular deps | âœ… | âœ… | âŒ |
| AI fixes (BYOK) | âœ… | âŒ | âŒ |
| Binary size | ~24MB | ~1GB | ~50MB |
| Free | âœ… | Limited | Limited |

## MCP Server

Repotoire includes an [MCP](https://modelcontextprotocol.io/) server for AI assistant integration:

```bash
repotoire serve
```

Tools: `analyze`, `get_findings`, `get_finding_detail`, `fix_finding`, `list_detectors`, `search_graph`, and more.

## License

MIT â€” see [LICENSE](LICENSE)

---

```bash
cargo install repotoire && repotoire analyze .
```
